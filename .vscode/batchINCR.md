Вот план.

## Что за фича

**Предварительное выделение ID (inode и chunk-ID) “батчами”**: вместо того чтобы запрашивать у Redis новый идентификатор на каждый создаваемый inode/срез (много `INCR`), клиент один раз делает `INCRBY` на N и получает **диапазон** ID. Эти ID расходуются локально из пула без дополнительных RTT. Это резко снижает число сетевых обращений при записи больших файлов и массовых созданиях.

---

## Пошаговый план реализации

### A. Подготовка и дизайн

1. **Зафиксировать ключи счётчиков**
   Определить/подтвердить имена ключей Redis для счётчиков: `nextInode`, `nextChunk` (или текущие из internals). Для Redis Cluster — сразу решить про hash-tag (`{jfs}:nextInode`, `{jfs}:nextChunk`), чтобы оба ключа жили в одном слоте.

2. **Определить параметры фичи**
   Ввести настройки (из URI):

   * `inode_batch` (default. 256),
   * `chunk_batch` (default. 2048),
   * `inode_low_watermark` / `chunk_low_watermark` (напр., 25% от батча),
   

3. **Границы ответственности**
   Принять, что:

   * Выделение диапазонов — **атомарно** через `INCRBY` на мастере.
   * «Дыры» в нумерации допустимы.
   * Никаких изменений в формате метаданных и существующей логике CSC/чтений.

### B. Изменения на уровне кода (структуры и API)

4. **Добавить пулы ID в `rueidis`-мета**
   В состоянии метадвижка ввести поля: база следующего ID, остаток в пуле, мьютекс и размеры батчей — **отдельно** для inode и chunk.

5. **Методы “прайминга”**
   Спроектировать два приватных метода: `primeInodes(n)` и `primeChunks(n)`, выполняющих `INCRBY` и возвращающих начало выделенного диапазона. Логика: новый максимум – n + расчёт стартового ID.

6. **Методы выдачи “следующего ID”**
   Спроектировать `nextInode()` и `nextChunkID()`, которые:

   * Берут под мьютексом ID из локального пула;
   * При опустошении пула вызывают соответствующий `prime*`;
   * Возвращают ID без похода к Redis в обычном случае.

7. **Низкий водяной знак (prefetch)**
   В `next*` добавить реакцию: если остаток в пуле ≤ low_watermark — асинхронно инициировать следующее `prime*` (без блокировки вызывающего пути).

8. **Инициализация батчей из конфигурации**
   Парсинг новых опций (URI) и установка дефолтов. Валидировать границы (минимум 1, максимум разумный).

### C. Интеграция в существующие пути

9. **Найти все места выделения inode**
   Локализовать все вызовы “получить новый inode” (ранее делали `INCR nextInode`) и заменить на `nextInode()`.

10. **Найти все места выделения chunk-ID**
    Аналогично заменить все обращения за новым chunk-ID на `nextChunkID()` (чаще встречается, даёт основной выигрыш).

11. **Сохранить существующую транзакционность**
    Убедиться, что замена **не нарушает** контракты, где раньше `INCR` был частью `WATCH/MULTI` (обычно `INCR` — внешний шаг, а не внутрь EXEC). Если где-то это было внутри, вынести “прайминг” до транзакции и передавать готовый ID внутрь.

12. **Поведение при ошибках Redis**
    Если `prime*` вернул ошибку — пробрасывать наверх; при асинхронном prefetch — логировать и повторять при следующем запросе. Локально уже выданные ID возвращать корректно, не дублировать.

13. **Параллелизм**
    Убедиться, что мьютексы стоят на критических секциях (выдача ID, обновление “базы” и “остатка”). Исключить double-prime при гонке (например, вторичная горутина увидит, что пулы уже пополнены).

### D. Совместимость и конфигурация

14. **Совместимость по умолчанию**
    По умолчанию включить фичу с консервативными батчами (например, inode=256, chunk=2048), чтобы “из коробки” было лучше без риска. Возможность выключить — через опции (для отката).

15. **Кластерный режим**
    Документировать требование hash-tag для счётчиков в Redis Cluster. Если кластер не используется — без изменений.

16. **Обсервабилити/метрики**
    Добавить счётчики:

    * `inode_prime_calls`, `inode_ids_from_pool`, `inode_pool_refill_async`,
    * `chunk_prime_calls`, `chunk_ids_from_pool`, `chunk_pool_refill_async`,
    * и `prime_errors`.
      Логи уровня debug при прайминге (start, size, остаток).

### E. Тесты (обязательно)

17. **Юнит-тест: корректность диапазонов**

    * `INCRBY` на N: проверить, что первый выданный ID = newMax − N + 1; последовательная выдача N штук уникальна;  N+1-й запрос инициирует новый `prime*`.
    * Пул не “перепрыгивает” и не дублирует.

18. **Юнит-тест: параллельность**

    * 10–100 конкурентных горутин запрашивают ID → все уникальны, без гонок, без зависаний.
    * Проверить, что не происходит двукратного `prime*` для одного пула (или это безопасно).

19. **Юнит-тест: низкий водяной знак**

    * Смоделировать падение остатка ниже watermark → должен стартовать async-prefetch.
    * Если параллельно кто-то уже праймит — второй префетч не стартует (или стартует, но корректно объединяется).

20. **Интеграционный тест: crash-recovery**

    * Зарезервировать батч, выдать часть ID, смоделировать “крэш” до исчерпания; после рестарта продолжить — убедиться, что никаких проблем нет (новый батч просто начнётся с нового диапазона; старые неиспользованные потеряны — это ожидаемо).

21. **Интеграционный тест: смешанный доступ**

    * Параллельно создавать файлы и большие последовательные записи (получая много chunk-ID). Проверить, что ID не конфликтуют и всё корректно сохраняется.

24. **Долговременный прогон (soak)**

    * Непрерывная запись множества больших файлов (разные размеры, 1–50 параллельных писателей) 2–6 часов. Наблюдать метрики (частота `prime_calls`, ошибки, размер пулов; кривая скорости записи — без провалов).

25. **Регресс-тесты функциональности**

    * Создание/удаление, rename, sparse-файлы, fsync, возобновление. Убедиться, что изменения в путях выдачи ID **ничего не сломали**.

### F. Документация и раскатка

26. **Документация**

    * Описать фичу, параметры, дефолты, ограничения (дыры в ID, требования к Redis Cluster).
    * Рекомендации по тюнингу `*_batch` под профили нагрузки.

27. **Фича-флаг и откат**

    * Иметь простой способ выключить (опция конфигурации) и подтвердить, что при выключении клиент возвращается к `INCR`-поведению без ребилда.


## Важные замечания/риски

* **Атомарность мета-операций не страдает:** мы меняем только способ получения ID; дальнейшие операции над метаданными остаются как были.
* **“Дыры” в ID — ожидаемы и безопасны.** Это не влияет на адресацию/поиск.
* **В кластере — только с hash-tags** (или держите счётчики на одном узле).
* **Выигрыш максимален для chunk-ID.** Там вызовов было больше всего → именно тут заметно “снимается” RTT.

